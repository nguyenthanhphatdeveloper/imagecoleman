#!/usr/bin/env python3
"""
Coleman async downloader
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Nh·∫≠p m√£ s·∫£n ph·∫©m th·ªß c√¥ng, queue cho ƒë·∫øn khi g√µ 'yes'
- T·∫£i ·∫£nh + m√¥ t·∫£ (JP) + d·ªãch sang TI·∫æNG VI·ªÜT
"""

import asyncio
import logging
import re
import sys
from pathlib import Path

import aiofiles

# Import tkinter cho file picker (c√≥ s·∫µn trong Python)
try:
    import tkinter as tk
    from tkinter import filedialog
    HAS_TKINTER = True
except ImportError:
    HAS_TKINTER = False
import aiohttp
from aiohttp import CookieJar
from bs4 import BeautifulSoup
from tqdm.asyncio import tqdm_asyncio
from deep_translator import GoogleTranslator

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
MAX_CONN = 10                  # t·ªïng socket ƒë·ªìng th·ªùi
MAX_RETRIES = 3                # s·ªë l·∫ßn th·ª≠ l·∫°i khi l·ªói
SLIDE_RANGE = range(1, 16)     # slide 1-15
SRC_LANG, DST_LANG = "ja", "vi"
translator = GoogleTranslator(source=SRC_LANG, target=DST_LANG)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LOGGING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.basicConfig(
    level=logging.INFO,
    format="%(levelname)-8s %(message)s",
    handlers=[logging.StreamHandler(),
              logging.FileHandler("download.log", encoding="utf-8")]
)
log = logging.getLogger("coleman")


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ NETWORK HELPERS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def get_headers(referer: str | None = None) -> dict:
    """T·∫°o headers gi·ªëng browser ƒë·ªÉ tr√°nh 403"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "none" if not referer else "same-origin",
        "Sec-Fetch-User": "?1",
        "Cache-Control": "max-age=0",
    }
    if referer:
        headers["Referer"] = referer
    return headers

async def fetch_html(product_id: str, session: aiohttp.ClientSession, 
                     retries: int = MAX_RETRIES) -> str | None:
    url = f"https://ec.coleman.co.jp/item/{product_id}.html"
    headers = get_headers()
    for attempt in range(retries):
        try:
            async with session.get(url, headers=headers, allow_redirects=True) as r:
                if r.status == 200:
                    return await r.text()
                elif r.status == 404:
                    log.error("%s ‚Äì kh√¥ng t√¨m th·∫•y (404)", product_id)
                    return None
                elif r.status == 403:
                    log.warning("%s ‚Äì HTTP 403 Forbidden (l·∫ßn th·ª≠ %d/%d) - C√≥ th·ªÉ b·ªã ch·∫∑n b·ªüi server", 
                              product_id, attempt + 1, retries)
                else:
                    log.warning("%s ‚Äì HTTP %s (l·∫ßn th·ª≠ %d/%d)", product_id, r.status, attempt + 1, retries)
        except asyncio.TimeoutError:
            log.warning("%s ‚Äì timeout (l·∫ßn th·ª≠ %d/%d)", product_id, attempt + 1, retries)
        except Exception as e:
            log.warning("%s ‚Äì l·ªói: %s (l·∫ßn th·ª≠ %d/%d)", product_id, e, attempt + 1, retries)
        
        if attempt < retries - 1:
            # Th√™m delay ƒë·ªÉ tr√°nh rate limiting, tƒÉng d·∫ßn theo s·ªë l·∫ßn th·ª≠
            delay = 2 ** attempt + 0.5  # Th√™m 0.5s base delay
            await asyncio.sleep(delay)
    
    log.error("%s ‚Äì th·∫•t b·∫°i sau %d l·∫ßn th·ª≠", product_id, retries)
    return None


async def download_image(url: str, path: Path,
                         session: aiohttp.ClientSession,
                         product_id: str, slide: int,
                         sem: asyncio.Semaphore,
                         retries: int = MAX_RETRIES):
    # Ki·ªÉm tra file ƒë√£ t·ªìn t·∫°i v√† c√≥ k√≠ch th∆∞·ªõc h·ª£p l·ªá
    if path.exists():
        try:
            if path.stat().st_size > 0:
                return  # File ƒë√£ t·ªìn t·∫°i v√† c√≥ d·ªØ li·ªáu
        except OSError:
            pass  # File c√≥ th·ªÉ b·ªã l·ªói, t·∫£i l·∫°i
    
    async with sem:
        # Headers cho ·∫£nh
        headers = get_headers(referer=f"https://ec.coleman.co.jp/item/{product_id}.html")
        headers.update({
            "Accept": "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8",
            "Sec-Fetch-Dest": "image",
            "Sec-Fetch-Mode": "no-cors",
        })
        
        for attempt in range(retries):
            try:
                async with session.get(url, headers=headers) as r:
                    if r.status == 200:
                        data = await r.read()
                        if len(data) > 0:  # Ki·ªÉm tra d·ªØ li·ªáu kh√¥ng r·ªóng
                            async with aiofiles.open(path, "wb") as f:
                                await f.write(data)
                            return  # Th√†nh c√¥ng
                        else:
                            log.warning("%s ‚Äì slide %d: d·ªØ li·ªáu r·ªóng", product_id, slide)
                    elif r.status == 404:
                        log.warning("%s ‚Äì slide %d kh√¥ng t·ªìn t·∫°i (404)", product_id, slide)
                        return  # Kh√¥ng c·∫ßn th·ª≠ l·∫°i cho 404
                    else:
                        log.warning("%s ‚Äì slide %d HTTP %s (l·∫ßn th·ª≠ %d/%d)", 
                                  product_id, slide, r.status, attempt + 1, retries)
            except asyncio.TimeoutError:
                log.warning("%s ‚Äì slide %d timeout (l·∫ßn th·ª≠ %d/%d)", 
                          product_id, slide, attempt + 1, retries)
            except Exception as e:
                log.warning("%s ‚Äì l·ªói slide %d: %s (l·∫ßn th·ª≠ %d/%d)", 
                          product_id, slide, e, attempt + 1, retries)
            
            if attempt < retries - 1:
                await asyncio.sleep(1 * (attempt + 1))  # Linear backoff
        
        log.error("%s ‚Äì slide %d th·∫•t b·∫°i sau %d l·∫ßn th·ª≠", product_id, slide, retries)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CORE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def translate_text(text: str) -> str:
    """D·ªãch text trong thread pool ƒë·ªÉ kh√¥ng block event loop"""
    loop = asyncio.get_event_loop()
    try:
        return await loop.run_in_executor(None, translator.translate, text)
    except Exception as e:
        log.error("L·ªói d·ªãch: %s", e)
        return text  # Tr·∫£ v·ªÅ text g·ªëc n·∫øu l·ªói

async def save_descriptions(soup: BeautifulSoup, out_dir: Path,
                            product_id: str):
    ul = soup.find("ul", class_="p-item_info_indt")
    if not ul:
        log.warning("%s ‚Äì kh√¥ng t√¨m <ul>", product_id)
        return
    jp_lines = [li.get_text(strip=True) for li in ul.find_all("li") if li.get_text(strip=True)]
    if not jp_lines:
        log.warning("%s ‚Äì <ul> r·ªóng", product_id)
        return

    # JP
    jp_path = out_dir / f"{product_id}.jp.txt"
    async with aiofiles.open(jp_path, "w", encoding="utf-8") as f:
        await f.write("\n".join(jp_lines))
    
    # VI - d·ªãch song song ƒë·ªÉ tƒÉng t·ªëc
    vi_tasks = [translate_text(line) for line in jp_lines]
    vi_lines = await asyncio.gather(*vi_tasks)
    
    vi_path = out_dir / f"{product_id}.vi.txt"
    async with aiofiles.open(vi_path, "w", encoding="utf-8") as f:
        await f.write("\n".join(vi_lines))
    log.info("%s ‚Äì ƒë√£ l∆∞u jp.txt & vi.txt", product_id)

async def handle_product(pid: str, session: aiohttp.ClientSession,
                         sem: asyncio.Semaphore):
    html = await fetch_html(pid, session)
    if html is None:
        return
    soup = BeautifulSoup(html, "html.parser")
    out_dir = Path(pid)
    out_dir.mkdir(exist_ok=True)

    # 1) M√¥ t·∫£
    await save_descriptions(soup, out_dir, pid)

    # 2) ·∫¢nh
    tasks = []
    for slide in SLIDE_RANGE:
        tag = soup.find(attrs={"data-slide": str(slide)})
        img_tag = tag.find("img") if tag else None
        src = img_tag["src"] if img_tag and img_tag.has_attr("src") else None
        if not src:
            log.warning("%s ‚Äì thi·∫øu slide %d", pid, slide)
            continue
        if src.startswith("//"):
            src = "https:" + src
        elif src.startswith("/"):
            src = "https://ec.coleman.co.jp" + src
        path = out_dir / f"{slide}.jpg"
        tasks.append(download_image(src, path, session, pid, slide, sem))

    if tasks:
        await tqdm_asyncio.gather(*tasks, desc=pid, unit="img")
    else:
        log.warning("%s ‚Äì kh√¥ng c√≥ ·∫£nh", pid)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ MAIN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def main(product_ids: list[str]):
    sem = asyncio.Semaphore(MAX_CONN)
    # T·ªëi ∆∞u connector: tƒÉng limit_per_host ƒë·ªÉ t·∫£i ·∫£nh nhanh h∆°n
    connector = aiohttp.TCPConnector(
        limit=MAX_CONN * 2,  # TƒÉng t·ªïng connection pool
        limit_per_host=MAX_CONN,  # Cho ph√©p nhi·ªÅu connection h∆°n ƒë·∫øn c√πng host
        ttl_dns_cache=300,  # Cache DNS 5 ph√∫t
        force_close=False  # T√°i s·ª≠ d·ª•ng connection
    )

    timeout = aiohttp.ClientTimeout(total=180, connect=30)
    
    # Headers m·∫∑c ƒë·ªãnh cho session (s·∫Ω ƒë∆∞·ª£c override b·ªüi headers c·ª• th·ªÉ trong m·ªói request)
    default_headers = get_headers()
    
    # S·ª≠ d·ª•ng CookieJar ƒë·ªÉ l∆∞u cookies v√† gi·ªØ session
    cookie_jar = CookieJar(unsafe=True)  # unsafe=True ƒë·ªÉ ch·∫•p nh·∫≠n cookies t·ª´ m·ªçi domain
    
    async with aiohttp.ClientSession(
        connector=connector, 
        timeout=timeout,
        headers=default_headers,
        cookie_jar=cookie_jar
    ) as sess:
        # Warm-up: request ƒë·∫øn trang ch·ªß ƒë·ªÉ l·∫•y cookies ban ƒë·∫ßu
        try:
            log.info("ƒêang kh·ªüi t·∫°o session...")
            async with sess.get("https://ec.coleman.co.jp/", headers=get_headers()) as r:
                if r.status == 200:
                    log.info("‚úì Session ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")
                else:
                    log.warning("‚ö†Ô∏è  Warm-up request tr·∫£ v·ªÅ HTTP %s", r.status)
        except Exception as e:
            log.warning("‚ö†Ô∏è  L·ªói warm-up: %s (ti·∫øp t·ª•c...)", e)
        
        tasks = [handle_product(pid, sess, sem) for pid in product_ids]
        await tqdm_asyncio.gather(*tasks, desc="T·ªïng ti·∫øn ƒë·ªô", unit="s·∫£n ph·∫©m")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ FILE PARSING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def select_file_dialog() -> str | None:
    """
    M·ªü h·ªôp tho·∫°i ch·ªçn file txt.
    Tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n file ho·∫∑c None n·∫øu h·ªßy.
    """
    if not HAS_TKINTER:
        return None
    
    try:
        # T·∫°o root window ·∫©n
        root = tk.Tk()
        root.withdraw()  # ·∫®n c·ª≠a s·ªï ch√≠nh
        root.attributes('-topmost', True)  # ƒê∆∞a l√™n tr√™n c√πng
        
        # M·ªü file dialog
        file_path = filedialog.askopenfilename(
            title="Ch·ªçn file txt ch·ª©a m√£ s·∫£n ph·∫©m",
            filetypes=[
                ("Text files", "*.txt"),
                ("All files", "*.*")
            ],
            initialdir="."  # B·∫Øt ƒë·∫ßu t·ª´ th∆∞ m·ª•c hi·ªán t·∫°i
        )
        
        root.destroy()  # ƒê√≥ng root window
        
        return file_path if file_path else None
    
    except Exception as e:
        log.error("L·ªói m·ªü file dialog: %s", e)
        return None

def parse_product_ids_from_file(file_path: str) -> list[str]:
    """
    ƒê·ªçc m√£ s·∫£n ph·∫©m t·ª´ file txt.
    H·ªó tr·ª£ c√°c ƒë·ªãnh d·∫°ng: d·∫•u ph·∫©y, xu·ªëng d√≤ng, ho·∫∑c d·∫•u c√°ch
    """
    try:
        path = Path(file_path)
        if not path.exists():
            log.error("File kh√¥ng t·ªìn t·∫°i: %s", file_path)
            return []
        
        content = path.read_text(encoding="utf-8")
        if not content.strip():
            log.warning("File r·ªóng: %s", file_path)
            return []
        
        # T√°ch theo nhi·ªÅu delimiter: d·∫•u ph·∫©y, xu·ªëng d√≤ng, d·∫•u c√°ch
        # S·ª≠ d·ª•ng regex ƒë·ªÉ t√°ch theo t·∫•t c·∫£ c√°c delimiter
        ids = re.split(r'[,\s\n]+', content)
        
        # L·ªçc v√† l√†m s·∫°ch: ch·ªâ l·∫•y s·ªë, lo·∫°i b·ªè r·ªóng
        product_ids = []
        for item in ids:
            cleaned = item.strip()
            if cleaned and cleaned.isdigit():
                product_ids.append(cleaned)
        
        # Lo·∫°i b·ªè tr√πng l·∫∑p nh∆∞ng gi·ªØ nguy√™n th·ª© t·ª±
        seen = set()
        unique_ids = []
        for pid in product_ids:
            if pid not in seen:
                seen.add(pid)
                unique_ids.append(pid)
        
        log.info("ƒê√£ ƒë·ªçc %d m√£ s·∫£n ph·∫©m t·ª´ file %s", len(unique_ids), file_path)
        return unique_ids
    
    except Exception as e:
        log.error("L·ªói ƒë·ªçc file %s: %s", file_path, e)
        return []

if __name__ == "__main__":
    queue: list[str] = []
    
    print("=" * 50)
    print("Coleman Product Downloader")
    print("=" * 50)
    print("Ch·ªçn ch·∫ø ƒë·ªô:")
    print("  1. Nh·∫≠p m√£ th·ªß c√¥ng")
    print("  2. ƒê·ªçc t·ª´ file txt")
    print("=" * 50)
    
    mode = input("Ch·ªçn (1 ho·∫∑c 2): ").strip()
    
    if mode == "2":
        # ƒê·ªçc t·ª´ file
        print("\nCh·ªçn file txt:")
        print("  1. Ch·ªçn file t·ª´ h·ªôp tho·∫°i (khuy·∫øn ngh·ªã)")
        print("  2. Nh·∫≠p ƒë∆∞·ªùng d·∫´n th·ªß c√¥ng")
        print("  3. D√πng file m·∫∑c ƒë·ªãnh 'products.txt'")
        
        choice = input("\nCh·ªçn (1/2/3): ").strip()
        file_path = None
        
        if choice == "1":
            # Ch·ªçn file t·ª´ dialog
            if not HAS_TKINTER:
                print("‚ö†Ô∏è  tkinter kh√¥ng kh·∫£ d·ª•ng, chuy·ªÉn sang nh·∫≠p th·ªß c√¥ng...")
                file_path = input("\nNh·∫≠p ƒë∆∞·ªùng d·∫´n file txt: ").strip()
                if not file_path:
                    print("‚ùå Kh√¥ng c√≥ ƒë∆∞·ªùng d·∫´n. Tho√°t.")
                    exit(1)
            else:
                print("\nüìÇ ƒêang m·ªü h·ªôp tho·∫°i ch·ªçn file...")
                file_path = select_file_dialog()
                if not file_path:
                    print("‚ùå Kh√¥ng ch·ªçn file. Tho√°t.")
                    exit(0)
                print(f"‚úì ƒê√£ ch·ªçn: {file_path}")
        
        elif choice == "2":
            # Nh·∫≠p ƒë∆∞·ªùng d·∫´n th·ªß c√¥ng
            file_path = input("\nNh·∫≠p ƒë∆∞·ªùng d·∫´n file txt: ").strip()
            if not file_path:
                print("‚ùå Kh√¥ng c√≥ ƒë∆∞·ªùng d·∫´n. Tho√°t.")
                exit(1)
        
        elif choice == "3":
            # D√πng file m·∫∑c ƒë·ªãnh
            file_path = "products.txt"
            print(f"‚úì S·ª≠ d·ª•ng file m·∫∑c ƒë·ªãnh: {file_path}")
        
        else:
            print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. Tho√°t.")
            exit(1)
        
        queue = parse_product_ids_from_file(file_path)
        if not queue:
            print(f"‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c m√£ n√†o t·ª´ file '{file_path}'")
            print("   Ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n v√† ƒë·ªãnh d·∫°ng file.")
            exit(1)
        
        print(f"\n‚úì ƒê√£ ƒë·ªçc {len(queue)} m√£ s·∫£n ph·∫©m t·ª´ file '{file_path}'")
        print(f"  Danh s√°ch: {', '.join(queue[:10])}{'...' if len(queue) > 10 else ''}")
        confirm = input("\nB·∫Øt ƒë·∫ßu t·∫£i? (yes/no): ").strip().lower()
        if confirm != "yes":
            print("ƒê√£ h·ªßy.")
            exit(0)
    
    elif mode == "1":
        # Nh·∫≠p th·ªß c√¥ng
        print("\nNh·∫≠p m√£ s·∫£n ph·∫©m (m·ªói m√£ m·ªôt d√≤ng), g√µ 'yes' ƒë·ªÉ b·∫Øt ƒë·∫ßu t·∫£i:")
        while True:
            s = input("> ").strip()
            if s.lower() == "yes":
                break
            elif s.isdigit():
                if s not in queue:  # Tr√°nh tr√πng l·∫∑p
                    queue.append(s)
                    print(f"‚úì ƒë√£ th√™m {s} (t·ªïng: {len(queue)})")
                else:
                    print(f"‚ö†Ô∏è  {s} ƒë√£ c√≥ trong danh s√°ch")
            else:
                print("‚ö†Ô∏è  ch·ªâ nh·∫≠p s·ªë ho·∫∑c 'yes'.")
    
    else:
        print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. Tho√°t.")
        exit(1)

    if not queue:
        print("Ch∆∞a c√≥ m√£ n√†o ‚ûú tho√°t.")
    else:
        print(f"\nüöÄ B·∫Øt ƒë·∫ßu t·∫£i {len(queue)} s·∫£n ph·∫©m...\n")
        asyncio.run(main(queue))
        print("\nüéâ  Xong! Ki·ªÉm tra c√°c th∆∞ m·ª•c s·∫£n ph·∫©m v√† file download.log.")
